{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian analyses and MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LF_p2 = LikelihoodFunction(lambda z, f_IGM, DM_host_0, alpha: model.DM_ext_th(z, DM_host_0,  None, None, None, f_IGM, alpha, 'p2'))\\nLF_p3 = LikelihoodFunction(lambda z, f_IGM, DM_host_0, alpha: model.DM_ext_th(z, DM_host_0,  None, None, None, f_IGM, alpha, 'p3'))\\nLF_p4 = LikelihoodFunction(lambda z, f_IGM, DM_host_0, s: model.DM_ext_th(z, DM_host_0,  None, None, None, f_IGM, s, 'p4'))\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from likelihood import Priors, LikelihoodFunction\n",
    "from equations import DM_EXT_model\n",
    "\n",
    "model = DM_EXT_model()\n",
    "\n",
    "# Defining the prior intervals manually\n",
    "intervals_constant = [(0, 1), (55, 225)]  # Interval for f_IGM and DM_host_0\n",
    "intervals_p2 = [(0, 1), (55, 225), (0, 5)]  # Intervals for f_IGM, DM_host_0 and alpha\n",
    "intervals_p3 = [(0, 1), (55, 225), (0, 5)]  # Intervals for f_IGM, DM_host_0 and alpha\n",
    "intervals_p4 = [(0, 1), (55, 225), (-5, 5)]  # Intervals for f_IGM, DM_host_0 and s\n",
    "\n",
    "# Creating specific instances of the priors\n",
    "P_constant = Priors(['$f_{IGM}$', '$DM_{host,0}$'], intervals_constant)\n",
    "P_p2 = Priors(['$f_{IGM}$', '$DM_{host,0}$', '$\\\\alpha$'], intervals_p2)\n",
    "P_p3 = Priors(['$f_{IGM}$', '$DM_{host,0}$', '$\\\\alpha$'], intervals_p3)\n",
    "P_p4 = Priors(['$f_{IGM}$', '$DM_{host,0}$', '$s$'], intervals_p4)\n",
    "\n",
    "# Creating an instance of the likelihood model\n",
    "#LF_constant = LikelihoodFunction(lambda z, f_IGM, DM_host_0: model.DM_ext_th(z=z, DM_host_0=DM_host_0, f_IGM=f_IGM, model_type='constant'))\n",
    "#LF_constant = LikelihoodFunction(lambda z, f_IGM, DM_host_0: model.DM_ext_th(z, DM_host_0, f_IGM=f_IGM, model_type='constant'))\n",
    "\n",
    "# Criando uma instância da função de verossimilhança para o modelo 'constant'\n",
    "LF_constant = LikelihoodFunction(\n",
    "    lambda z, f_IGM, DM_host_0: model.DM_ext_th(z=z, DM_host_0=DM_host_0, f_IGM=f_IGM, model_type='constant', Omega_b=None, Omega_m=None, H_today=None, param=None)\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"LF_p2 = LikelihoodFunction(lambda z, f_IGM, DM_host_0, alpha: model.DM_ext_th(z, DM_host_0,  None, None, None, f_IGM, alpha, 'p2'))\n",
    "LF_p3 = LikelihoodFunction(lambda z, f_IGM, DM_host_0, alpha: model.DM_ext_th(z, DM_host_0,  None, None, None, f_IGM, alpha, 'p3'))\n",
    "LF_p4 = LikelihoodFunction(lambda z, f_IGM, DM_host_0, s: model.DM_ext_th(z, DM_host_0,  None, None, None, f_IGM, s, 'p4'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m dm_ext_errors \u001b[38;5;241m=\u001b[39m  DM_obs_ext_error_16\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Configuring the ultranest samplers\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#sampler_constant = ultranest.ReactiveNestedSampler(P_constant.param_names, lambda params: LF_constant.log_likelihood(params=params, z_values=z_values, y_obs=dm_ext_obs, errors=dm_ext_errors), P_constant.prior_transform)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Configurando o sampler ultranest\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m sampler_constant \u001b[38;5;241m=\u001b[39m \u001b[43multranest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReactiveNestedSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP_constant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Os nomes dos parâmetros a serem otimizados (f_IGM e DM_host_0)\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLF_constant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm_ext_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm_ext_errors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP_constant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior_transform\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"sampler_p2 = ultranest.ReactiveNestedSampler(P_p2.param_names,\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    lambda params: LF_p2.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p2.prior_transform)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03msampler_p4 = ultranest.ReactiveNestedSampler(P_p4.param_names,\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    lambda params: LF_p4.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p4.prior_transform)\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ultranest/integrator.py:1208\u001b[0m, in \u001b[0;36mReactiveNestedSampler.__init__\u001b[0;34m(self, param_names, loglike, transform, derived_param_names, wrapped_params, resume, run_num, log_dir, num_test_samples, draw_multiple, num_bootstraps, vectorized, ndraw_min, ndraw_max, storage_backend, warmstart_max_tau)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndraw_max \u001b[38;5;241m=\u001b[39m ndraw_max\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_tregion \u001b[38;5;241m=\u001b[39m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_likelihood_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglike\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_test_samples\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to_disk\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resume_similar \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to_disk:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ultranest/integrator.py:1270\u001b[0m, in \u001b[0;36mReactiveNestedSampler._check_likelihood_function\u001b[0;34m(self, transform, loglike, num_test_samples)\u001b[0m\n\u001b[1;32m   1266\u001b[0m p \u001b[38;5;241m=\u001b[39m transform(u) \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m u\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(p) \u001b[38;5;241m==\u001b[39m (num_test_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_params), (\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in transform function: returned shape is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m   1269\u001b[0m         np\u001b[38;5;241m.\u001b[39mshape(p), (num_test_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_params)))\n\u001b[0;32m-> 1270\u001b[0m logl \u001b[38;5;241m=\u001b[39m \u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlogical_and(u \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, u \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mall(), (\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in transform function: u was modified!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(logl) \u001b[38;5;241m==\u001b[39m (num_test_samples,), (\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in loglikelihood function: returned shape is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, expected \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (np\u001b[38;5;241m.\u001b[39mshape(logl), (num_test_samples,)))\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ultranest/utils.py:137\u001b[0m, in \u001b[0;36mvectorize.<locals>.vectorized\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvectorized\u001b[39m(args):\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Vectorized version of function.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args])\n",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     12\u001b[0m dm_ext_errors \u001b[38;5;241m=\u001b[39m  DM_obs_ext_error_16\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Configuring the ultranest samplers\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#sampler_constant = ultranest.ReactiveNestedSampler(P_constant.param_names, lambda params: LF_constant.log_likelihood(params=params, z_values=z_values, y_obs=dm_ext_obs, errors=dm_ext_errors), P_constant.prior_transform)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Configurando o sampler ultranest\u001b[39;00m\n\u001b[1;32m     17\u001b[0m sampler_constant \u001b[38;5;241m=\u001b[39m ultranest\u001b[38;5;241m.\u001b[39mReactiveNestedSampler(\n\u001b[1;32m     18\u001b[0m     P_constant\u001b[38;5;241m.\u001b[39mparam_names,  \u001b[38;5;66;03m# Os nomes dos parâmetros a serem otimizados (f_IGM e DM_host_0)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m params: \u001b[43mLF_constant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm_ext_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm_ext_errors\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     20\u001b[0m     P_constant\u001b[38;5;241m.\u001b[39mprior_transform\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"sampler_p2 = ultranest.ReactiveNestedSampler(P_p2.param_names,\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    lambda params: LF_p2.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p2.prior_transform)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03msampler_p4 = ultranest.ReactiveNestedSampler(P_p4.param_names,\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    lambda params: LF_p4.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p4.prior_transform)\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/cosmology_reconstruction_frb/likelihood.py:35\u001b[0m, in \u001b[0;36mLikelihoodFunction.log_likelihood\u001b[0;34m(self, params, z_values, y_obs, errors, err_neg, err_pos)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, z_values, y_obs, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, err_neg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, err_pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Extração dos parâmetros\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     f_IGM, DM_host_0, model_type, Omega_b, Omega_m, H_today, param \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# Compute the model values\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     y_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_func(z_values, f_IGM, DM_host_0, model_type, Omega_b, Omega_m, H_today, param)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 2)"
     ]
    }
   ],
   "source": [
    "from obs_data import FRB_data\n",
    "import ultranest\n",
    "\n",
    "# Instantiate the FRB_data class for 16 FRBs\n",
    "frb_data_16 = FRB_data(n_frb=16)\n",
    "\n",
    "# Call the select_data method to get the observed data\n",
    "z_obs_16, DM_obs_ext_16, DM_obs_ext_error_16 = frb_data_16.select_data()\n",
    "\n",
    "z_values = z_obs_16\n",
    "dm_ext_obs = DM_obs_ext_16\n",
    "dm_ext_errors =  DM_obs_ext_error_16\n",
    "\n",
    "# Configuring the ultranest samplers\n",
    "#sampler_constant = ultranest.ReactiveNestedSampler(P_constant.param_names, lambda params: LF_constant.log_likelihood(params=params, z_values=z_values, y_obs=dm_ext_obs, errors=dm_ext_errors), P_constant.prior_transform)\n",
    "# Configurando o sampler ultranest\n",
    "sampler_constant = ultranest.ReactiveNestedSampler(\n",
    "    P_constant.param_names,  # Os nomes dos parâmetros a serem otimizados (f_IGM e DM_host_0)\n",
    "    lambda params: LF_constant.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors),\n",
    "    P_constant.prior_transform\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"sampler_p2 = ultranest.ReactiveNestedSampler(P_p2.param_names,\n",
    "    lambda params: LF_p2.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p2.prior_transform)\n",
    "\n",
    "sampler_p3 = ultranest.ReactiveNestedSampler(P_p3.param_names,\n",
    "    lambda params: LF_p3.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p3.prior_transform)\n",
    "\n",
    "sampler_p4 = ultranest.ReactiveNestedSampler(P_p4.param_names,\n",
    "    lambda params: LF_p4.log_likelihood(params, z_values, dm_ext_obs, dm_ext_errors, None, None), P_p4.prior_transform)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = sampler_constant.run(min_num_live_points=400)\n",
    "sampler_constant.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = sampler_p2.run(min_num_live_points=400)\n",
    "sampler_p2.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = sampler_p3.run(min_num_live_points=400)\n",
    "sampler_p3.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = sampler_p4.run(min_num_live_points=400)\n",
    "sampler_p4.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdist import plots, MCSamples\n",
    "\n",
    "# Extraindo amostras dos resultados\n",
    "samples1 = result1['samples']\n",
    "samples2 = result2['samples']\n",
    "samples3 = result3['samples']\n",
    "samples4 = result4['samples']\n",
    "\n",
    "# Criando objetos MCSamples com os dados\n",
    "labels1 = ['f_{IGM,0}']\n",
    "names1 = ['f_IGM']\n",
    "mcsamples1 = MCSamples(samples=samples1, names=names1, labels=labels1)\n",
    "\n",
    "labels2 = ['f_{IGM,0}', '\\\\alpha']\n",
    "names2 = ['f_IGM', 'alpha']\n",
    "mcsamples2 = MCSamples(samples=samples2, names=names2, labels=labels2)\n",
    "mcsamples3 = MCSamples(samples=samples3, names=names2, labels=labels2)\n",
    "\n",
    "labels3 = ['f_{IGM,0}', 's']\n",
    "names3 = ['f_IGM', 's']\n",
    "mcsamples4 = MCSamples(samples=samples4, names=names3, labels=labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os Triangle plots\n",
    "g = plots.get_subplot_plotter()\n",
    "mcsamples1.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot(mcsamples1, filled=True, contour_colors=['green'], \n",
    "                legend_labels=['P. 1'], \n",
    "                title_limit=1)\n",
    "g.export('Figuras/H_p1.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os Triangle plots\n",
    "g = plots.get_subplot_plotter()\n",
    "mcsamples2.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot(mcsamples2, filled=True, contour_colors=['red'],\n",
    "                legend_labels=['P. 2'], title_limit=1)\n",
    "g.export('Figuras/H_p2.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os Triangle plots\n",
    "g = plots.get_subplot_plotter()\n",
    "mcsamples3.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot(mcsamples3, filled=True, contour_colors=['blue'],\n",
    "                legend_labels=['P. 3'], title_limit=1)\n",
    "g.export('Figuras/H_p3.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os Triangle plots\n",
    "g = plots.get_subplot_plotter()\n",
    "mcsamples4.updateSettings({'smooth_scale_2D': 0.9, 'smooth_scale_1D': 0.9})\n",
    "g.settings.num_plot_contours = 2\n",
    "g.triangle_plot(mcsamples4, filled=True, contour_colors=['purple'],\n",
    "                legend_labels=['P. 4'], title_limit=1)\n",
    "g.export('Figuras/H_p4.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultranest.plot import PredictionBand\n",
    "from equations import H_Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('$H(z)$')\n",
    "plt.errorbar(x=z_values, y=H_obs, yerr=errors, marker='o', alpha=0.6, capsize=3, ls=' ', color='red', label='Data', ms=4)\n",
    "\n",
    "z_test = np.linspace(0, 2, 100)\n",
    "\n",
    "band = PredictionBand(z_test)\n",
    "model = H_Model()\n",
    "# go through the solutions\n",
    "for f_IGM, alpha  in sampler_p3.results['samples']:\n",
    "    # compute for each time the y value\n",
    "    band.add(model.H_p(z_test, f_IGM, alpha, 'p3', 'ANN'))\n",
    "\n",
    "band.line(color='k', linestyle='-', label='Parameterization 3', linewidth=1.5)\n",
    "# add 1 sigma quantile\n",
    "band.shade(color='green', alpha=0.3)\n",
    "# add wider quantile (0.01 .. 0.99)\n",
    "band.shade(q=0.49, color='green', alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('Figuras/H_bestfit.png', format='png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Load data: X, Y, and associated errors\n",
    "DM_IGM = np.loadtxt('data/DM_IGM_detected_bingo+mirror_4m_alpha=-1.5_5yrs_with_erros.txt', skiprows=1)\n",
    "x = DM_IGM[:, 0]\n",
    "y = DM_IGM[:, 1]\n",
    "y_err = DM_IGM[:, 2]\n",
    "\n",
    "# Ajuste de um polinômio de grau 3 (por exemplo) aos dados\n",
    "degree = 3  # Você pode ajustar o grau conforme necessário\n",
    "coeffs = np.polyfit(x, y, degree)\n",
    "\n",
    "# Cria a função polinomial a partir dos coeficientes ajustados\n",
    "poly_fit = np.poly1d(coeffs)\n",
    "\n",
    "# Avalia o polinômio ajustado para novos valores de x\n",
    "x_new = np.linspace(min(x), max(x), 100)\n",
    "y_new = poly_fit(x_new)\n",
    "\n",
    "# Cubic spline interpolation\n",
    "cs = CubicSpline(x_new, y_new)\n",
    "\n",
    "# First derivative of the spline\n",
    "cs_derivative = cs.derivative()\n",
    "\n",
    "# Reconstructed function and its derivative\n",
    "y_new = cs(x_new)\n",
    "y_derivative_new = cs_derivative(x_new)\n",
    "\n",
    "# Propagating errors (simplified for interpolation)\n",
    "# Assuming independent errors and approximating them for the interpolated data\n",
    "y_new_err = np.interp(x_new, x, y_err)  # Interpolating errors for y\n",
    "y_derivative_err = np.gradient(y_new_err, x_new)  # Approximating error propagation for derivative\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Dados originais com erros\n",
    "plt.errorbar(x, y, yerr=y_err, fmt='o', label='Dados originais', color='red', alpha=0.6, markersize=4)\n",
    "\n",
    "# Polinômio ajustado\n",
    "plt.plot(x_new, y_new, label=f'Fit Polinomial (grau {degree})', color='k')\n",
    "\n",
    "# Área de erro aproximado usando o erro médio\n",
    "plt.fill_between(x_new, y_new - y_err.mean(), y_new + y_err.mean(), color='green', alpha=0.6, label='Erro interpolado (aproximado)')\n",
    "\n",
    "# Rótulos e detalhes do gráfico\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first derivative\n",
    "plt.plot(x_new, y_derivative_new, label='First Derivative', color='green')\n",
    "plt.fill_between(x_new, y_derivative_new - y_derivative_err, y_derivative_new + y_derivative_err, \n",
    "                 color='green', alpha=0.2, label=r'1$\\sigma$ (derivative)')\n",
    "plt.fill_between(x_new, y_derivative_new - 2*y_derivative_err, y_derivative_new + 2*y_derivative_err, \n",
    "                 color='green', alpha=0.1, label=r'2$\\sigma$ (derivative)')\n",
    "plt.ylim(ymin=600, ymax=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
